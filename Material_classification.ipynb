{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"can\",\"bottle\"]\n",
    "for label in labels:\n",
    "    os.makedirs(f'material_classification/train/{label}')\n",
    "    os.makedirs(f'material_classification/val/{label}')\n",
    "    os.makedirs(f'material_classification/test/{label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottle_train_count = 0\n",
    "bottle_val_count = 0\n",
    "bottle_test_count = 0\n",
    "can_train_count = 0\n",
    "can_val_count = 0\n",
    "can_test_count = 0\n",
    "\n",
    "sub_dir = [\"coca cola can\", \"coca cola plastic bottle\", \"fanta can\", \n",
    "           \"fanta plastic bottle\", \"7up can\", \"7up plastic bottle\"]\n",
    "for d in sub_dir:\n",
    "    if d.split()[-1] == \"bottle\":\n",
    "        for f in os.listdir(f'DATA/data/{d}'):\n",
    "            if bottle_train_count < 2400:\n",
    "                shutil.copy(f'DATA/data/{d}/'+f,f'material_classification/train/bottle/{bottle_train_count}.jpg')\n",
    "                bottle_train_count += 1\n",
    "            elif bottle_val_count < 300:\n",
    "                shutil.copy(f'DATA/data/{d}/'+f,f'material_classification/val/bottle/{bottle_val_count}.jpg')\n",
    "                bottle_val_count += 1\n",
    "            elif bottle_test_count < 300:\n",
    "                shutil.copy(f'DATA/data/{d}/'+f,f'material_classification/test/bottle/{bottle_test_count}.jpg')\n",
    "                bottle_test_count += 1\n",
    "    elif d.split()[-1] == \"can\":\n",
    "        for f in os.listdir(f'DATA/data/{d}'):\n",
    "            if can_train_count < 2400:\n",
    "                shutil.copy(f'DATA/data/{d}/'+f,f'material_classification/train/can/{can_train_count}.jpg')\n",
    "                can_train_count += 1\n",
    "            elif can_val_count < 300:\n",
    "                shutil.copy(f'DATA/data/{d}/'+f,f'material_classification/val/can/{can_val_count}.jpg')\n",
    "                can_val_count += 1\n",
    "            elif can_test_count < 300:\n",
    "                shutil.copy(f'DATA/data/{d}/'+f,f'material_classification/test/can/{can_test_count}.jpg')\n",
    "                can_test_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import models, transforms, datasets\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_transform = transforms.Compose([\n",
    "  transforms.Resize(256),\n",
    "  transforms.CenterCrop(224),\n",
    "  transforms.RandomRotation(30),\n",
    "  transforms.RandomHorizontalFlip(),\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'material_classification/train'\n",
    "val_dir = 'material_classification/val'\n",
    "test_dir = 'material_classification/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train, validation and test dataset\n",
    "train_dataset = datasets.ImageFolder(train_dir,transform=dataset_transform)\n",
    "val_dataset = datasets.ImageFolder(val_dir,transform=dataset_transform)\n",
    "test_dataset = datasets.ImageFolder(test_dir,transform=dataset_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets into dataloader for iteration\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = 100, shuffle = True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size = 100, shuffle = True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = 100, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def training(model):\n",
    "    iteration = 0\n",
    "    minLoss = float(\"inf\")\n",
    "    best_parameters = None\n",
    "\n",
    "    # Training Loop\n",
    "    for epoch in range(epochs):\n",
    "        # Iterate over the training dataloader\n",
    "        for i, (images, labels) in enumerate(train_dataloader):\n",
    "            # Reinitialize the gradient\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Get the correct label\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward propagation\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Use the loss for back propagation\n",
    "            loss.backward()\n",
    "\n",
    "            # Update network parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Empty the cache of GPU\n",
    "            del images\n",
    "            del labels\n",
    "            del loss\n",
    "            del outputs\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            iteration += 1\n",
    "\n",
    "            if iteration % 10 == 0 or iteration == 1:\n",
    "                # Calculate Accuracy and loss        \n",
    "                correct = 0\n",
    "                total = 0\n",
    "\n",
    "                total_loss = 0\n",
    "\n",
    "                # Validation Loop\n",
    "                # Iterate over the validation dataloader\n",
    "                for images, labels in val_dataloader:\n",
    "\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    # Make prediction\n",
    "                    outputs = model(images)\n",
    "\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    total_loss += float(loss)\n",
    "\n",
    "                    # Get predictions from the maximum value, index 0 is the maximum value, \n",
    "                    # index 1 is the index of the maximum value\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                    # Number of labels\n",
    "                    total += labels.size(0)\n",
    "\n",
    "                    # Number of correct predictions\n",
    "                    correct += (predicted == labels).sum()\n",
    "                    \n",
    "                    # Empty cache of GPU\n",
    "                    del images\n",
    "                    del labels\n",
    "                    del loss\n",
    "                    del outputs\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                # Calculate accuracy\n",
    "                accuracy = 100 * correct / total\n",
    "\n",
    "                # Save parameters if loss is smaller\n",
    "                if total_loss < minLoss:\n",
    "                    minLoss = total_loss\n",
    "                    best_parameters = model.state_dict()\n",
    "\n",
    "                # Print accuracy and loss\n",
    "                print(f'Iteration {iteration}: Loss: {total_loss}, Validation accuracy: {accuracy}')\n",
    "    return best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Testing\n",
    "def test(model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "    count = 0\n",
    "\n",
    "    # Test Loop\n",
    "    for images, labels in test_dataloader:\n",
    "\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Make prediction\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += float(loss)\n",
    "\n",
    "        # Get predictions from the maximum value, index 0 is the maximum value, \n",
    "        # index 1 is the index of the maximum value\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Number of labels\n",
    "        total += labels.size(0)\n",
    "\n",
    "        # Number of correct predictions\n",
    "        correct += (predicted == labels).sum()\n",
    "        incorrect = images[predicted != labels]\n",
    "        \n",
    "        # Show 5 wrong predicted example\n",
    "        if count < 5 and (predicted == labels).sum() != labels.size(0):\n",
    "            \n",
    "            wrong = \"dog\" if predicted[predicted != labels][0] else \"cat\"\n",
    "            actual = \"dog\" if labels[predicted != labels][0] else \"cat\"\n",
    "            print(f\"Predicted {wrong}\")\n",
    "            print(f\"Actual {actual}\")\n",
    "            show_image = incorrect[0].cpu().numpy().transpose((1, 2, 0))\n",
    "            plt.imshow(show_image, cmap='gray')\n",
    "            plt.show()\n",
    "            count += 1\n",
    "        \n",
    "        # Empty cache\n",
    "        del images\n",
    "        del labels\n",
    "        del loss\n",
    "        del outputs\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    # Print accuracy and loss\n",
    "    print(f'Best model has Loss: {total_loss}, Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet = models.alexnet(pretrained=True)\n",
    "alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet.classifier[6] = nn.Linear(in_features=4096, out_features=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only unfreeze the last two layer\n",
    "to_update = [\"classifier.6.weight\", \"classifier.6.bias\"]\n",
    "to_update_params = []\n",
    "for name, param in alexnet.named_parameters():\n",
    "    if name in to_update:\n",
    "        param.requires_grad = True\n",
    "        to_update_params.append(param)\n",
    "    else:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "epochs = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params=to_update_params, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "alexnet = alexnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Loss: 39.91987943649292, Validation accuracy: 50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\anaconda3\\lib\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10: Loss: 13.61647891998291, Validation accuracy: 72.5\n",
      "Iteration 20: Loss: 12.186755061149597, Validation accuracy: 67.0\n",
      "Iteration 30: Loss: 8.397380590438843, Validation accuracy: 75.33333587646484\n",
      "Iteration 40: Loss: 10.339252710342407, Validation accuracy: 70.0\n",
      "Iteration 50: Loss: 7.222352862358093, Validation accuracy: 73.16667175292969\n",
      "Iteration 60: Loss: 7.052318453788757, Validation accuracy: 77.66667175292969\n",
      "Iteration 70: Loss: 9.669580578804016, Validation accuracy: 78.0\n",
      "Iteration 80: Loss: 8.248022675514221, Validation accuracy: 77.16667175292969\n",
      "Iteration 90: Loss: 8.230790257453918, Validation accuracy: 74.33333587646484\n",
      "Iteration 100: Loss: 7.5921560525894165, Validation accuracy: 76.66667175292969\n",
      "Iteration 110: Loss: 7.402311682701111, Validation accuracy: 76.5\n",
      "Iteration 120: Loss: 8.001210987567902, Validation accuracy: 75.16667175292969\n",
      "Iteration 130: Loss: 6.787102103233337, Validation accuracy: 77.83333587646484\n",
      "Iteration 140: Loss: 6.99583637714386, Validation accuracy: 76.83333587646484\n",
      "Iteration 150: Loss: 6.5600773096084595, Validation accuracy: 79.66667175292969\n",
      "Iteration 160: Loss: 7.947941780090332, Validation accuracy: 77.33333587646484\n",
      "Iteration 170: Loss: 9.411540627479553, Validation accuracy: 76.5\n",
      "Iteration 180: Loss: 8.679431200027466, Validation accuracy: 77.33333587646484\n",
      "Iteration 190: Loss: 8.42732298374176, Validation accuracy: 75.5\n",
      "Iteration 200: Loss: 7.791473984718323, Validation accuracy: 79.33333587646484\n",
      "Iteration 210: Loss: 8.814805030822754, Validation accuracy: 78.83333587646484\n",
      "Iteration 220: Loss: 7.860271751880646, Validation accuracy: 78.83333587646484\n",
      "Iteration 230: Loss: 8.825107991695404, Validation accuracy: 77.33333587646484\n",
      "Iteration 240: Loss: 9.993530869483948, Validation accuracy: 79.16667175292969\n",
      "Iteration 250: Loss: 11.385594129562378, Validation accuracy: 75.83333587646484\n",
      "Iteration 260: Loss: 15.553472518920898, Validation accuracy: 71.0\n",
      "Iteration 270: Loss: 10.915440082550049, Validation accuracy: 78.66667175292969\n",
      "Iteration 280: Loss: 7.365239858627319, Validation accuracy: 80.5\n",
      "Iteration 290: Loss: 7.762416183948517, Validation accuracy: 81.0\n",
      "Iteration 300: Loss: 6.606954276561737, Validation accuracy: 82.16667175292969\n",
      "Iteration 310: Loss: 8.673148214817047, Validation accuracy: 79.33333587646484\n",
      "Iteration 320: Loss: 7.626167118549347, Validation accuracy: 79.5\n",
      "Iteration 330: Loss: 7.76281601190567, Validation accuracy: 81.33333587646484\n",
      "Iteration 340: Loss: 7.884363770484924, Validation accuracy: 82.16667175292969\n",
      "Iteration 350: Loss: 8.682650208473206, Validation accuracy: 80.0\n",
      "Iteration 360: Loss: 8.85340565443039, Validation accuracy: 81.83333587646484\n",
      "Iteration 370: Loss: 9.538264751434326, Validation accuracy: 76.66667175292969\n",
      "Iteration 380: Loss: 11.520797491073608, Validation accuracy: 75.5\n",
      "Iteration 390: Loss: 12.032105326652527, Validation accuracy: 80.16667175292969\n",
      "Iteration 400: Loss: 11.291209697723389, Validation accuracy: 78.0\n",
      "Iteration 410: Loss: 9.961865782737732, Validation accuracy: 79.16667175292969\n",
      "Iteration 420: Loss: 10.535636305809021, Validation accuracy: 76.83333587646484\n",
      "Iteration 430: Loss: 10.81136679649353, Validation accuracy: 76.33333587646484\n",
      "Iteration 440: Loss: 11.858765959739685, Validation accuracy: 76.83333587646484\n",
      "Iteration 450: Loss: 8.613107919692993, Validation accuracy: 78.83333587646484\n",
      "Iteration 460: Loss: 7.4342328906059265, Validation accuracy: 84.0\n",
      "Iteration 470: Loss: 11.480313420295715, Validation accuracy: 75.66667175292969\n",
      "Iteration 480: Loss: 9.098638713359833, Validation accuracy: 81.0\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "alexnet_best_parameters = training(alexnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GoogleNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "googlenet = models.googlenet(pretrained=True)\n",
    "googlenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "googlenet.fc = nn.Linear(in_features=1024, out_features=3, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only unfreeze the last two layer\n",
    "to_update = [\"fc.weight\", \"fc.bias\"]\n",
    "to_update_params = []\n",
    "for name, param in googlenet.named_parameters():\n",
    "    if name in to_update:\n",
    "        param.requires_grad = True\n",
    "        to_update_params.append(param)\n",
    "    else:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "epochs = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params=to_update_params, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "googlenet = googlenet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "googlenet_best_parameters = training(googlenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model params\n",
    "torch.save(googlenet_best_parameters, ModelPath+'/googlenet_params.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "googlenet.load_state_dict(torch.load(\"./best_models/googlenet_params.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(googlenet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchensemble import VotingClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_vote = VotingClassifier(estimator=alexnet, n_estimators=10)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "ensemble_vote.set_criterion(criterion)\n",
    "ensemble_vote.set_optimizer(\"Adam\", lr=0.01)\n",
    "ensemble_vote.fit(train_dataloader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = 100, shuffle = True)\n",
    "test(ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble different models\n",
    "class diff_vote_classifier():\n",
    "    def __init__(self, *args):\n",
    "        self.models = [model for model in args]\n",
    "        self.n = len(self.models)\n",
    "        \n",
    "    def __call__(images):\n",
    "        output = self.models[0](images) \n",
    "        for ind in range(1,len(self.models)):\n",
    "            model = self.models[ind]\n",
    "            output += model(images) # torch.add\n",
    "        output = output/float(self.n)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_voter = diff_vote_classifier(alexnet, googlenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(diff_voter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
